# -*- coding: utf-8 -*-
"""Basics_of_Stats.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tH5_2MbzsBm1NaE86F31wsO99gmaZdgM

1. To compute and analyze basic statistical measures for numerical columns in the dataset.
"""

import pandas as pd
import numpy as np

df = pd.read_csv('/content/sales_data_with_discounts.csv')

print("\n Dataset loaded successfully!")
print("\n Preview of Dataset:")
display(df.head())

print("\n Dataset Information:")
df.info()

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
print("\n Numerical Columns Found:")
print(numeric_cols)

print("\n Descriptive Statistics:")
desc_stats = df[numeric_cols].describe().T
display(desc_stats)

print("\n Mode for Numerical Columns:")
mode_values = df[numeric_cols].mode().iloc[0]
display(mode_values)

print("\n Standard Deviation:")
std_dev = df[numeric_cols].std()
display(std_dev)

print("\n Interpretation Summary:")
for col in numeric_cols:
    mean_val = df[col].mean()
    median_val = df[col].median()
    mode_val = df[col].mode()[0]
    std_val = df[col].std()
    print(f"\nâž¡ Column: {col}")
    print(f"   Mean: {mean_val:.2f}")
    print(f"   Median: {median_val:.2f}")
    print(f"   Mode: {mode_val:.2f}")
    print(f"   Std Dev: {std_val:.2f}")
    print("   Interpretation:")
    print("   - Mean: Represents the average value of the data.")
    print("   - Median: Central point of data, less affected by outliers.")
    print("   - Mode: The most frequently occurring value.")
    print("   - Standard Deviation: Shows how much the data varies from the mean.")

print("\n Checking Missing Values:")
missing_values = df.isnull().sum()
display(missing_values)

if missing_values.sum() > 0:
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())
    print("\n Missing numeric values filled using column mean.")
else:
    print("\n No missing values found in the dataset.")

df.to_csv('/content/cleaned_sales_data.csv', index=False)
print("\n Cleaned dataset saved as 'cleaned_sales_data.csv' successfully.")

"""2. To visualize the distribution and relationship of numerical and categorical variables in the dataset."""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('cleaned_sales_data.csv')

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()

for col in numeric_cols:
    plt.figure(figsize=(7, 4))
    sns.histplot(df[col], kde=True, bins=20)
    plt.title(f'Histogram of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()

for col in numeric_cols:
    plt.figure(figsize=(6, 4))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
    plt.xlabel(col)
    plt.show()

for col in categorical_cols:
    plt.figure(figsize=(7, 4))
    sns.countplot(x=df[col])
    plt.title(f'Bar Chart of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=45)
    plt.show()

"""To scale numerical variables for uniformity, improving the datasetâ€™s"""

from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

df = pd.read_csv('/content/cleaned_sales_data.csv')

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
scaler = StandardScaler()
scaled_values = scaler.fit_transform(df[numeric_cols])
df_scaled = df.copy()
df_scaled[numeric_cols] = scaled_values

for col in numeric_cols:
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    sns.histplot(df[col], kde=True, bins=20)
    plt.title(f'Original Distribution of {col}')
    plt.subplot(1, 2, 2)
    sns.histplot(df_scaled[col], kde=True, bins=20, color='orange')
    plt.title(f'Standardized Distribution of {col}')
    plt.show()

""": To transform categorical variables into a format that can be"""

import pandas as pd

df = pd.read_csv('/content/cleaned_sales_data.csv')

categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

print("\nâœ… One-hot encoding applied successfully!")
print("\nðŸ”¹ Preview of Transformed Dataset:")
display(df_encoded.head())

"""Conclusion:
Descriptive analytics provided insights into numerical data distributions, central tendencies, and spread. Data visualizations like histograms, boxplots, and bar charts helped identify patterns, outliers, and category distributions. Standardization ensured numerical features are on a uniform scale, improving suitability for ML models. One-hot encoding transformed categorical features into numeric binary variables, enabling seamless input to ML algorithms. Overall, these preprocessing steps prepare the dataset for accurate and efficient predictive modeling.
"""